{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальное задание по практике\n",
    "--------------------\n",
    "\n",
    "### Цель\n",
    "\n",
    "Ознакомится с базовыми алгоритмами и базовыми инструментами машинного обучения для анализа и классификации текста.\n",
    "\n",
    "### Задание\n",
    "\n",
    "1) Получить категоризованные данные с <b>Facebook API</b><br>\n",
    "2) Сохранить полученные данные<br>\n",
    "3) Токенизация данных<br>\n",
    "4) Удаление стоп-слов<br>\n",
    "5) Стемминг<br>\n",
    "6) Поиск паттерна имя-фамилия в тексте<br>\n",
    "7) Формирование списка топ <i>100</i> важных токенов по каждой категории<br>\n",
    "8) Категоризация новых текстов по наличию в них этих топ <i>100</i> токенов<br>\n",
    "9) Оценка качества<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодировка для кода на <b>Python</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измирения времени работы некоторых участоков подключим модуль <b>\"time\"</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time as t\n",
    "\n",
    "# вернет: текущее время в миллисекундах\n",
    "def time(): return int(round(t.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хранение данных\n",
    "\n",
    "Для хранения данных была выбрана база данных <b>Elasticsearch</b>, которая предоставляет удобный интерфейс взаимодействия, а так же кроссплатформенность при работе с ней, за счет того, что взаимодействие осуществляется по HTTP протоколу.\n",
    "\n",
    "Константы работы с базой данных <b>Elasticsearch</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ES_INDEX = \"fb_group_posts\"                 # Аналог базы данных в сравнении с реляционными БД, под ним будут\n",
    "                                            # хранится все данные, необходимые по заданию\n",
    "ES_POST_DOC_TYPE = \"post\"                   \n",
    "ES_NAME_RELATION_DOC_TYPE = \"name_relation\"\n",
    "\n",
    "ES_BULK_ACTIONS_SIZE = 500                  # Размер пака данных отсылаемых за раз в elasticsearch, \n",
    "                                            # необходимо для оптимизации по скорости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с базой данных не относится к заданию напрямую, по-этому описанию работе с ней уделено меньше внимания. Вся работа с <b>Elasticsearch</b> скрыта в ниже описанном классе <b>FacebookDBHelper</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import TransportError\n",
    "from elasticsearch import helpers\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Дата-класс, который описывает отношение наличия имени в тексте поста\n",
    "# @param: fl_name - Имя Фамилия\n",
    "# @param: post_id - id поста, в тексте которого содержится это имя и фамилия\n",
    "class FLNameData(object):\n",
    "    def __init__(self, fl_name, post_id):\n",
    "        self.fl_name = fl_name\n",
    "        self.post_id = post_id\n",
    "\n",
    "\n",
    "class FacebookDBHelper(object):\n",
    "    def __init__(self):\n",
    "        self.es = Elasticsearch()\n",
    "    \n",
    "    def save_posts(self, group_name, group_domain, posts):\n",
    "        actions = []\n",
    "\n",
    "        for post in posts:\n",
    "            if 'message' in post.keys():\n",
    "                action = {\n",
    "                    \"_index\": ES_INDEX,\n",
    "                    \"_type\": ES_POST_DOC_TYPE,\n",
    "                    \"_id\": post['id'],\n",
    "                    \"_source\": {\n",
    "                        \"message\": post['message'],\n",
    "                        \"group_name\": group_name,\n",
    "                        \"group_domain\": group_domain\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                actions.append(action)\n",
    "\n",
    "        self.__bulk_insert(actions)\n",
    "        \n",
    "    def save_name_relations(self, relations):\n",
    "        actions = []\n",
    "\n",
    "        for relation in relations:\n",
    "            action = {\n",
    "                \"_index\": ES_INDEX,\n",
    "                \"_type\": ES_NAME_RELATION_DOC_TYPE,\n",
    "                \"_source\": {\n",
    "                    \"fl_name\": relation.fl_name,\n",
    "                    \"post_id\": relation.post_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            actions.append(action)\n",
    "\n",
    "        self.__bulk_insert(actions)\n",
    "\n",
    "    def __bulk_insert(self, actions):\n",
    "        actions_list = split_list(list(actions), ES_BULK_ACTIONS_SIZE)\n",
    "\n",
    "        for acts in actions_list:\n",
    "            helpers.bulk(self.es, acts)\n",
    "\n",
    "    def get_post_by_id(self, id):\n",
    "        return self.__get(doc_type=ES_POST_DOC_TYPE, id=id)\n",
    "\n",
    "    def get_all_posts(self):\n",
    "        return self.__get_all(doc_type=ES_POST_DOC_TYPE)\n",
    "\n",
    "    def get_all_name_relations(self, doc_type):\n",
    "        relations = self.__get_all(doc_type=doc_type)\n",
    "\n",
    "        # noinspection PyTypeChecker\n",
    "        return [FLNameData(fl_name=r['_source']['fl_name'], post_id=r[\"_id\"]) for r in relations]\n",
    "\n",
    "    def __get(self, doc_type, id):\n",
    "        return self.es.get(index=ES_INDEX, doc_type=doc_type, id=id)\n",
    "\n",
    "    def __get_all(self, doc_type, body=None):\n",
    "        if body is None:\n",
    "            body = {}\n",
    "\n",
    "        result = []\n",
    "\n",
    "        page = self.es.search(\n",
    "            index=ES_INDEX,\n",
    "            doc_type=doc_type,\n",
    "            scroll='2m',\n",
    "            search_type='scan',\n",
    "            size=1000,\n",
    "            body=body)\n",
    "\n",
    "        scroll_id = page['_scroll_id']\n",
    "        scroll_size = page['hits']['total']\n",
    "\n",
    "        while scroll_size > 0:\n",
    "            page = self.es.scroll(scroll_id=scroll_id, scroll='2m')\n",
    "\n",
    "            scroll_id = page['_scroll_id']\n",
    "            scroll_size = len(page['hits']['hits'])\n",
    "\n",
    "            result.extend(page['hits']['hits'])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_all_sources(self, doc_type):\n",
    "        posts = self.get_all_posts()\n",
    "        result = []\n",
    "\n",
    "        for post in posts:\n",
    "            if \"_source\" in post.keys():\n",
    "                # noinspection PyTypeChecker\n",
    "                result.append(post[\"_source\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_all_messages(self):\n",
    "        sources = self.get_all_sources(doc_type=ES_POST_DOC_TYPE)\n",
    "        result = []\n",
    "\n",
    "        for source in sources:\n",
    "            if 'message' in source.keys():\n",
    "                # noinspection PyTypeChecker\n",
    "                result.append(source[\"message\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def delete_all_posts(self):\n",
    "        return delete_by_doc_type(\n",
    "            es=self.es,\n",
    "            index=ES_INDEX,\n",
    "            type_=ES_POST_DOC_TYPE)\n",
    "\n",
    "    def delete_all_name_relations(self):\n",
    "        return delete_by_doc_type(\n",
    "            es=self.es,\n",
    "            index=ES_INDEX,\n",
    "            type_=ES_NAME_RELATION_DOC_TYPE)\n",
    "\n",
    "    def get_messages_by_domain(self, domain):\n",
    "        posts = self.__get_all(doc_type=ES_POST_DOC_TYPE, body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"group_domain\": {\n",
    "                        \"query\": domain,\n",
    "                        \"operator\": \"and\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        return [p['_source']['message'] for p in posts]\n",
    "\n",
    "    def get_name_relations_by_fl(self, fl_name):\n",
    "        return self.__get_all(doc_type=ES_NAME_RELATION_DOC_TYPE, body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"fl_name\": {\n",
    "                        \"query\": fl_name,\n",
    "                        \"operator\": \"and\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    def get_all_domains(self):\n",
    "        response = self.es.search(index=ES_INDEX, doc_type=ES_POST_DOC_TYPE, body={\n",
    "            \"size\": 0,\n",
    "            \"aggs\": {\n",
    "                \"langs\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"group_domain\",\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for bucket in response['aggregations']['langs']['buckets']:\n",
    "            result.append(bucket['key'])\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def delete_by_doc_type(es, index, type_):\n",
    "    try:\n",
    "        count = es.count(index, type_)['count']\n",
    "        max_count = 5000\n",
    "\n",
    "        if not count:\n",
    "            return 0\n",
    "\n",
    "        tmp_count = count\n",
    "\n",
    "        while tmp_count > 0:\n",
    "            tmp_count -= max_count\n",
    "\n",
    "            response = es.search(\n",
    "                index=index,\n",
    "                filter_path=[\"hits.hits._id\"],\n",
    "                body={\"size\": max_count,\n",
    "                      \"query\": {\n",
    "                          \"filtered\": {\n",
    "                              \"filter\": {\n",
    "                                    \"type\": {\"value\": type_}\n",
    "                              }\n",
    "                          }\n",
    "                      }})\n",
    "\n",
    "            if not response:\n",
    "                return 0\n",
    "\n",
    "            ids = [x[\"_id\"] for x in response[\"hits\"][\"hits\"]]\n",
    "\n",
    "            if not ids:\n",
    "                return 0\n",
    "\n",
    "            bulk_body = [\n",
    "                '{{\"delete\": {{\"_index\": \"{}\", \"_type\": \"{}\", \"_id\": \"{}\"}}}}'.format(index, type_, x)\n",
    "                for x in ids]\n",
    "\n",
    "            es.bulk('\\n'.join(bulk_body))\n",
    "            es.indices.flush_synced([index])\n",
    "\n",
    "        return count\n",
    "    except TransportError as ex:\n",
    "        print(\"Elasticsearch error: \" + ex.error)\n",
    "        raise ex\n",
    "        \n",
    "def split_list(list_, count_):\n",
    "    result = []\n",
    "\n",
    "    if len(list_) == 0:\n",
    "        return result\n",
    "\n",
    "    if len(list_) == count_:\n",
    "        result.append(list_)\n",
    "\n",
    "        return result\n",
    "\n",
    "    steps = len(list_) / count_\n",
    "    tmp_list = deepcopy(list_)\n",
    "\n",
    "    for i in range(0, steps):\n",
    "        result.append(tmp_list[0: count_])\n",
    "        tmp_list = tmp_list[count_: len(tmp_list)]\n",
    "\n",
    "    if len(tmp_list) != 0:\n",
    "        result.append(tmp_list)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экземпляр класса <b>FacebookDBHelper</b>, через который мы будем взаимодействовать с <b>Elasticsearch</b> во всей работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdb = FacebookDBHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка постов с facebook.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с fecebook.com я выбрал <b>Facebook Graph API</b>, <b>SDK</b> предоставляющее выскоуровневый интерфейс.\n",
    "\n",
    "Константы для работы с <b>Facebook API</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Токен зарегестрированного приложения в консоли разработчика на facebook.com\n",
    "FACEBOOK_TOKEN = \"1769775703259571|736fc7f9c5dc31707d40709a1d37813b\"\n",
    "\n",
    "# Кол-во постов загружаемых с одной группы на facebook.com\n",
    "FACEBOOK_POSTS_COUNT = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сущьность описывающая заведомо известные данные о группе в <b>Facebook</b>:\n",
    "* Имя\n",
    "* Id на facebook.com\n",
    "* Домен (класс) тематики группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, name, id, domain):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.domain = domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список групп, которые будут использованы для работы (для загрузки постов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = [\n",
    "    Group(name=\"CNN Politics\", id=\"219367258105115\", domain=\"politics\"),\n",
    "    Group(name=\"SinoRuss\", id=\"1565161760380398\", domain=\"politics\"),\n",
    "    Group(name=\"Politics & Sociology\", id=\"1616754815303974\", domain=\"politics\"),\n",
    "    Group(name=\"CNN Money\", id=\"6651543066\", domain=\"finances\"),\n",
    "    Group(name=\"MoneyMagazine\", id=\"119930514707114\", domain=\"finances\"),\n",
    "    Group(name=\"MTV\", id=\"7245371700\", domain=\"music\"),\n",
    "    Group(name=\"MTV UK\", id=\"15713980389\", domain=\"music\"),\n",
    "    Group(name=\"CNET\", id=\"7155422274\", domain=\"tech\"),\n",
    "    Group(name=\"TechCrunch\", id=\"8062627951\", domain=\"tech\"),\n",
    "    Group(name=\"TechCrunchEurope\", id=\"279044985158\", domain=\"tech\"),\n",
    "    Group(name=\"TechInsider\", id=\"352751268256569\", domain=\"tech\"),\n",
    "    Group(name=\"Sport Addicts\", id=\"817513368382866\", domain=\"sport\"),\n",
    "    Group(name=\"Pokemon GO\", id=\"1745029562403910\", domain=\"pokemon_go\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с Facebook будем использовать экземпляр класса <b>GraphAPI</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from facebook import GraphAPI\n",
    "\n",
    "\n",
    "graph = GraphAPI(access_token=FACEBOOK_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же нам понадобится модуль для совершения <b>HTTP</b> запросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция загружающая последовательно посты пока не достигнет предела группы или ограничения по кол-ву (константа <b>FACEBOOK_POSTS_COUNT</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_next_posts(posts, max_count):\n",
    "    result = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        if count > max_count: # Если зугрузили необходимое кол-во то прекращаем работу\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            for post_data in posts['data']: # Под ключем 'data' хранится список постов в паке\n",
    "                keys = post_data.keys()     # Так как мы нам нужны сами сообщения\n",
    "                                            \n",
    "                \n",
    "                if 'message' in keys:       # Добавляем в результат только те у которых есть\n",
    "                    result.append(post_data)# текстовое сообщение (смотрим поналичию ключа 'message')\n",
    "\n",
    "            # Меняем размер запрашиваемого пака (страницы) с постами, в уже сформированном запросе \n",
    "            # от Facebook Graph API.\n",
    "            request = posts['paging']['next'].replace(\"limit=25\", \"limit=100\")\n",
    "\n",
    "            # Выполняем запрос на получение следующей страницы с вопросами\n",
    "            s_time = time()\n",
    "            posts = requests.get(request).json()\n",
    "            f_time = time()\n",
    "            \n",
    "            posts_count = len(posts['data'])\n",
    "            count += posts_count\n",
    "            \n",
    "            print \"Время загрузки пака постов ->\", (f_time - s_time), \"|\", \"кол-во:\", posts_count, \"|\", \"всего:\", count\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    print \"Общее кол-во загруженных постов группы ->\", count\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя ранее описанный список постов заполняем нашу базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время загрузки данных [ CNN Politics ] группы -> 748\n",
      "Время загрузки первого пака постов -> 671\n",
      "Время загрузки пака постов -> 774 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 927 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1753 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1723 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 6548 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1521 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1411 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1585 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1545 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1631 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1645 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1552 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1696 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1446 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1554 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1532 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1504 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1427 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1514 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1532 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1437 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1505 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1506 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1504 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1555 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1499 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1426 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1537 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1523 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1547 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1371 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1565 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1508 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1461 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1585 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1453 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1558 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1398 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1500 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1609 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1401 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 6476\n",
      "-------------------------\n",
      "Время загрузки данных [ International Friends of China & Russia ] группы -> 640\n",
      "Время загрузки первого пака постов -> 1024\n",
      "Время загрузки пака постов -> 1158 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1343 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1429 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1506 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1533 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1823 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1807 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1785 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1676 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1606 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1739 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1658 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1589 | кол-во: 99 | всего: 1299\n",
      "Время загрузки пака постов -> 6741 | кол-во: 100 | всего: 1399\n",
      "Время загрузки пака постов -> 1728 | кол-во: 100 | всего: 1499\n",
      "Время загрузки пака постов -> 1386 | кол-во: 87 | всего: 1586\n",
      "Время загрузки пака постов -> 1523 | кол-во: 100 | всего: 1686\n",
      "Время загрузки пака постов -> 2845 | кол-во: 100 | всего: 1786\n",
      "Время загрузки пака постов -> 1568 | кол-во: 99 | всего: 1885\n",
      "Время загрузки пака постов -> 1736 | кол-во: 100 | всего: 1985\n",
      "Время загрузки пака постов -> 1581 | кол-во: 100 | всего: 2085\n",
      "Время загрузки пака постов -> 1554 | кол-во: 100 | всего: 2185\n",
      "Время загрузки пака постов -> 1594 | кол-во: 100 | всего: 2285\n",
      "Время загрузки пака постов -> 1447 | кол-во: 100 | всего: 2385\n",
      "Время загрузки пака постов -> 1583 | кол-во: 100 | всего: 2485\n",
      "Время загрузки пака постов -> 2960 | кол-во: 100 | всего: 2585\n",
      "Время загрузки пака постов -> 1352 | кол-во: 100 | всего: 2685\n",
      "Время загрузки пака постов -> 1537 | кол-во: 100 | всего: 2785\n",
      "Время загрузки пака постов -> 1529 | кол-во: 100 | всего: 2885\n",
      "Время загрузки пака постов -> 1397 | кол-во: 100 | всего: 2985\n",
      "Время загрузки пака постов -> 1525 | кол-во: 100 | всего: 3085\n",
      "Время загрузки пака постов -> 1564 | кол-во: 100 | всего: 3185\n",
      "Время загрузки пака постов -> 1434 | кол-во: 100 | всего: 3285\n",
      "Время загрузки пака постов -> 1563 | кол-во: 100 | всего: 3385\n",
      "Время загрузки пака постов -> 1463 | кол-во: 100 | всего: 3485\n",
      "Время загрузки пака постов -> 1386 | кол-во: 91 | всего: 3576\n",
      "Время загрузки пака постов -> 1248 | кол-во: 99 | всего: 3675\n",
      "Время загрузки пака постов -> 1463 | кол-во: 100 | всего: 3775\n",
      "Время загрузки пака постов -> 1458 | кол-во: 93 | всего: 3868\n",
      "Время загрузки пака постов -> 1410 | кол-во: 95 | всего: 3963\n",
      "Время загрузки пака постов -> 1473 | кол-во: 100 | всего: 4063\n",
      "Общее кол-во загруженных постов группы -> 4063\n",
      "Время сохранение постов в БД -> 1897\n",
      "-------------------------\n",
      "Время загрузки данных [ Politics & Sociology: Afterbirth ] группы -> 461\n",
      "Время загрузки первого пака постов -> 767\n",
      "Время загрузки пака постов -> 1060 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1258 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1123 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1971 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1265 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1021 | кол-во: 56 | всего: 556\n",
      "Время загрузки пака постов -> 950 | кол-во: 63 | всего: 619\n",
      "Время загрузки пака постов -> 900 | кол-во: 70 | всего: 689\n",
      "Время загрузки пака постов -> 946 | кол-во: 70 | всего: 759\n",
      "Время загрузки пака постов -> 1090 | кол-во: 64 | всего: 823\n",
      "Время загрузки пака постов -> 996 | кол-во: 64 | всего: 887\n",
      "Время загрузки пака постов -> 1013 | кол-во: 81 | всего: 968\n",
      "Время загрузки пака постов -> 1306 | кол-во: 79 | всего: 1047\n",
      "Время загрузки пака постов -> 945 | кол-во: 86 | всего: 1133\n",
      "Время загрузки пака постов -> 5735 | кол-во: 71 | всего: 1204\n",
      "Время загрузки пака постов -> 461 | кол-во: 0 | всего: 1204\n",
      "Общее кол-во загруженных постов группы -> 1204\n",
      "Время сохранение постов в БД -> 552\n",
      "-------------------------\n",
      "Время загрузки данных [ CNNMoney ] группы -> 638\n",
      "Время загрузки первого пака постов -> 735\n",
      "Время загрузки пака постов -> 821 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 5744 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 877 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 889 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 2079 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1966 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1741 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1504 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1592 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1718 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 6696 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1773 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1781 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1851 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1736 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1759 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1493 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1915 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1721 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1782 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1605 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1779 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1787 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1752 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1730 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1635 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 6549 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1751 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1749 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1641 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1835 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1693 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 6784 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1622 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1795 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1785 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 6616 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1785 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1577 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1831 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 6542 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2073\n",
      "-------------------------\n",
      "Время загрузки данных [ Money Magazine ] группы -> 639\n",
      "Время загрузки первого пака постов -> 757\n",
      "Время загрузки пака постов -> 869 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 896 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 918 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 3085 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 2738 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1844 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1826 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1814 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 6699 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1729 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1677 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1755 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1557 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1898 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1687 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1790 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1681 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1666 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 2062 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1761 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1624 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1804 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1949 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1571 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1749 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1645 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1695 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 6489 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1613 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1731 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1622 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1844 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1776 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1731 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1768 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1590 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1749 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1795 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1726 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1551 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1568 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2889\n",
      "-------------------------\n",
      "Время загрузки данных [ MTV ] группы -> 468\n",
      "Время загрузки первого пака постов -> 752\n",
      "Время загрузки пака постов -> 808 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 862 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 947 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 905 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 2315 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 2066 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1954 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1915 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1936 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1863 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1819 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1758 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1960 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 2085 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 2017 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1754 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1797 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1906 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1879 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1886 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 6800 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1943 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1834 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1878 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1956 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1725 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 2137 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1906 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1926 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1873 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 7029 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1953 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 6882 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1814 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1950 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1970 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1903 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1917 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1932 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1867 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1999 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2037\n",
      "-------------------------\n",
      "Время загрузки данных [ MTV UK ] группы -> 578\n",
      "Время загрузки первого пака постов -> 689\n",
      "Время загрузки пака постов -> 837 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 2301 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 2255 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1737 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1773 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1726 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1843 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1678 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1633 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1829 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1667 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1651 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1748 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1868 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1671 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1898 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1811 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1845 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1819 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1681 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1805 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1825 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1782 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1761 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1774 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1827 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1866 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 2063 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1793 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1816 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1891 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 6698 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1693 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1709 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1765 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 6510 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1659 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1818 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1725 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1979 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1708 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2094\n",
      "-------------------------\n",
      "Время загрузки данных [ CNET ] группы -> 563\n",
      "Время загрузки первого пака постов -> 10559\n",
      "Время загрузки пака постов -> 1209 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1375 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1469 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1554 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1485 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1546 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1511 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1465 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1634 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1519 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1545 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1500 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1679 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 6706 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1527 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1672 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1588 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1476 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1751 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1775 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1610 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1628 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1676 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1564 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1705 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1555 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1691 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1495 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1464 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1513 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1538 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1389 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1726 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1707 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1451 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1494 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1558 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1435 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1712 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1672 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 6471 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 1788\n",
      "-------------------------\n",
      "Время загрузки данных [ TechCrunch ] группы -> 593\n",
      "Время загрузки первого пака постов -> 10494\n",
      "Время загрузки пака постов -> 938 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 975 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1332 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 2151 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1785 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1895 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1745 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1964 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1686 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1790 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1727 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1787 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1750 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1887 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1697 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1872 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1873 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1729 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1822 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 2145 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 6775 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1873 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1827 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1891 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1730 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1838 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1718 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1978 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1781 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1641 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1816 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 1848 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1756 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1807 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1783 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1706 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1739 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1625 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1854 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 6804 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1932 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2268\n",
      "-------------------------\n",
      "Время загрузки данных [ TechCrunchEurope ] группы -> 634\n",
      "Время загрузки первого пака постов -> 1110\n",
      "Время загрузки пака постов -> 1179 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 961 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 6099 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 6133 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1108 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1063 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 5349 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 5260 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 2950 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 3994 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 4839 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 3491 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 5229 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 4091 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 5883 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 4449 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 4149 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 4763 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 4390 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 3647 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 4246 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 3047 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 2637 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 5051 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 4886 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 2007 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 3128 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 3450 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 4253 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 3811 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 2373 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 4917 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 3432 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 7864 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 1984 | кол-во: 69 | всего: 3469\n",
      "Время загрузки пака постов -> 1153 | кол-во: 0 | всего: 3469\n",
      "Общее кол-во загруженных постов группы -> 3469\n",
      "Время сохранение постов в БД -> 573\n",
      "-------------------------\n",
      "Время загрузки данных [ Tech Insider ] группы -> 1067\n",
      "Время загрузки первого пака постов -> 1108\n",
      "Время загрузки пака постов -> 892 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 932 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 997 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1067 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1156 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 1264 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1160 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1159 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1232 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1199 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1214 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1347 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1091 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1185 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1294 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1136 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1186 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1154 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1277 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 1255 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 1098 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1203 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1188 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1327 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1249 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 1383 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1270 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1264 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1454 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1488 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1185 | кол-во: 100 | всего: 3100\n",
      "Время загрузки пака постов -> 6343 | кол-во: 100 | всего: 3200\n",
      "Время загрузки пака постов -> 1398 | кол-во: 100 | всего: 3300\n",
      "Время загрузки пака постов -> 1229 | кол-во: 100 | всего: 3400\n",
      "Время загрузки пака постов -> 6290 | кол-во: 100 | всего: 3500\n",
      "Время загрузки пака постов -> 1164 | кол-во: 100 | всего: 3600\n",
      "Время загрузки пака постов -> 1141 | кол-во: 100 | всего: 3700\n",
      "Время загрузки пака постов -> 1227 | кол-во: 100 | всего: 3800\n",
      "Время загрузки пака постов -> 1256 | кол-во: 100 | всего: 3900\n",
      "Время загрузки пака постов -> 1122 | кол-во: 100 | всего: 4000\n",
      "Время загрузки пака постов -> 1188 | кол-во: 100 | всего: 4100\n",
      "Общее кол-во загруженных постов группы -> 4100\n",
      "Время сохранение постов в БД -> 2228\n",
      "-------------------------\n",
      "Время загрузки данных [ Sports Addicts ] группы -> 453\n",
      "Время загрузки первого пака постов -> 714\n",
      "Время загрузки пака постов -> 1047 | кол-во: 98 | всего: 98\n",
      "Время загрузки пака постов -> 6019 | кол-во: 94 | всего: 192\n",
      "Время загрузки пака постов -> 6183 | кол-во: 87 | всего: 279\n",
      "Время загрузки пака постов -> 958 | кол-во: 81 | всего: 360\n",
      "Время загрузки пака постов -> 1127 | кол-во: 87 | всего: 447\n",
      "Время загрузки пака постов -> 1097 | кол-во: 88 | всего: 535\n",
      "Время загрузки пака постов -> 1108 | кол-во: 95 | всего: 630\n",
      "Время загрузки пака постов -> 1199 | кол-во: 100 | всего: 730\n",
      "Время загрузки пака постов -> 1163 | кол-во: 91 | всего: 821\n",
      "Время загрузки пака постов -> 1260 | кол-во: 100 | всего: 921\n",
      "Время загрузки пака постов -> 1113 | кол-во: 92 | всего: 1013\n",
      "Время загрузки пака постов -> 1374 | кол-во: 95 | всего: 1108\n",
      "Время загрузки пака постов -> 1084 | кол-во: 95 | всего: 1203\n",
      "Время загрузки пака постов -> 1097 | кол-во: 93 | всего: 1296\n",
      "Время загрузки пака постов -> 743 | кол-во: 53 | всего: 1349\n",
      "Время загрузки пака постов -> 623 | кол-во: 0 | всего: 1349\n",
      "Общее кол-во загруженных постов группы -> 1349\n",
      "Время сохранение постов в БД -> 754\n",
      "-------------------------\n",
      "Время загрузки данных [ Pokémon GO Malta - Official ] группы -> 454\n",
      "Время загрузки первого пака постов -> 744\n",
      "Время загрузки пака постов -> 1088 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1117 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1102 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 801 | кол-во: 83 | всего: 383\n",
      "Время загрузки пака постов -> 528 | кол-во: 0 | всего: 383\n",
      "Общее кол-во загруженных постов группы -> 383\n",
      "Время сохранение постов в БД -> 336\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    # Получаем данные о группе по ее id на facebook.com\n",
    "    s_time = time()\n",
    "    group_json = graph.get_object(group.id)\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки данных [', group_json['name'], '] группы ->', (f_time - s_time)\n",
    "    \n",
    "    # Получаем первый пак постов, используем уже для этого метод \"get_connections\"\n",
    "    # который, грубо говоря, дает возможность запрашивать списки\n",
    "    s_time = time()\n",
    "    first_posts_pack = graph.get_connections(group_json['id'], 'feed')\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки первого пака постов ->', (f_time - s_time)\n",
    "    \n",
    "    # Последовательно загружаем все последующие посты\n",
    "    posts = load_next_posts(posts=first_posts_pack, max_count=FACEBOOK_POSTS_COUNT)\n",
    "    \n",
    "    # Сохраняем все в базу данных\n",
    "    s_time = time()\n",
    "    fdb.save_posts(group.name, group.domain, posts)\n",
    "    f_time = time()\n",
    "    \n",
    "    print \"Время сохранение постов в БД ->\", (f_time - s_time)\n",
    "    print \"-------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск паттерна (шаблона) \"Имя Фамилия\"\n",
    "\n",
    "Решение построено на том, что бы разбить поиск на  два основных этапа:\n",
    "1. Подготовить данные к поиску\n",
    "2. Выполнить сам поиск\n",
    "\n",
    "Подготовка в данном случае - это поиск всех пар <b>\"имя фамилия\"</b> заранее и кеширование свзяей <b>\"имя фамилия\" -> \"id поста\"</b> в базе данных. Это необходимо, что бы не осуществлять поиск в каждом посте при каждом запросе, а просто искать совпадения в уже найденных.\n",
    "\n",
    "### Подготовка данных к поиску\n",
    "\n",
    "Поиск имен выполнен с использованием регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Регулярное выражение для \"Имя Фамилия\"\n",
    "FIRST_LAST_NAME_PATTERN = \"[A-Z]{1}[a-z]+\\s+[A-Z]{1}[a-z]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем пользоваться уже сохраненными данными (текст постов, которые мы сохранили в базу данных <b>Elasticsearch</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = fdb.get_all_posts() # Вытаскиваем все посты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можем выполнить поиск имен по шаблону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время поиска имен по регулярному выражению -> 373\n",
      "Кол-во найденных совпадений по регулярному выраженияю: 40118\n"
     ]
    }
   ],
   "source": [
    "name_relations = []\n",
    "\n",
    "s_time = time()\n",
    "\n",
    "for post in posts:\n",
    "    message = post['_source']['message']\n",
    "    names = re.findall(FIRST_LAST_NAME_PATTERN, message)\n",
    "\n",
    "    if names:\n",
    "        id = post['_id']\n",
    "\n",
    "        for name in names:\n",
    "            name = name.replace(\".\", \"\")\n",
    "            relation = FLNameData(fl_name=name, post_id=id)\n",
    "            name_relations.append(relation)\n",
    "\n",
    "f_time = time()\n",
    "\n",
    "print \"Время поиска имен по регулярному выражению ->\", (f_time - s_time)\n",
    "print \"Кол-во найденных совпадений по регулярному выраженияю:\", len(name_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку все отношения будут хранить в базе данных, а предыдущим шагом были найдены пары \"имя фамилия\" во всех постах, то и очистим существующие связи, если они там есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время удаления старых отношений 'сообщение <=> имя' -> 8516\n",
      "Удалено старых отношений: 30340\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "deleted_posts = fdb.delete_all_name_relations()\n",
    "f_time = time()\n",
    "\n",
    "print \"Время удаления старых отношений 'сообщение <=> имя' ->\", (f_time - s_time)\n",
    "print \"Удалено старых отношений:\", deleted_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время сохранения новых отношений 'текст поста <=> имя' -> 20405\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "fdb.save_name_relations(name_relations)\n",
    "f_time = time()\n",
    "\n",
    "print \"Время сохранения новых отношений 'текст поста <=> имя' ->\", (f_time - s_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда все связи сохранены, мы можем осуществить поиск. В случае пополнения данных, необходимо находить все связи при добавлении их в базу данных \"имя фамилия\" и так же кешировать.\n",
    "\n",
    "### Поиск\n",
    "\n",
    "Ход действий таков:\n",
    "1. Сделать запрос в базу данных, что бы достать все свзязи в которых имя совпадает с запрашиваемым\n",
    "2. Получить id групп из результата (пункт 1)\n",
    "3. По найденным id групп мы теперь можем получить посты, тексты которых содержат запрашиваемые имена.\n",
    "\n",
    "Для демонстрации было взято предположительно самое популярное имя <i>\"Donald Trump\"</i> (имя, которое не сходит с уст СМИ), так как большинство сохраненных постов относятся к домену \"Политика\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имя [ John Kerry ] найдено соответстивий (сообщений): 19\n",
      "Имя [ Paul Reichler ] найдено соответстивий (сообщений): 10\n",
      "Имя [ Donald Trump ] найдено соответстивий (сообщений): 227\n"
     ]
    }
   ],
   "source": [
    "# Список имен для поиска\n",
    "searched_names = [\n",
    "    \"John Kerry\",\n",
    "    \"Paul Reichler\",\n",
    "    \"Donald Trump\"\n",
    "]\n",
    "\n",
    "def find_messages_by_fl_name(fl_name):\n",
    "    finded_relations = fdb.get_name_relations_by_fl(fl_name=fl_name)\n",
    "    messages = []\n",
    "    finded_post_ids = set() # Необходимо, что бы учитывать ранее найденные посты\n",
    "\n",
    "    for relation in finded_relations:\n",
    "        post_id = relation['_source']['post_id']\n",
    "\n",
    "        if not post_id in finded_post_ids:\n",
    "            finded_post_ids.add(post_id)\n",
    "            \n",
    "            message = fdb.get_post_by_id(post_id)['_source']['message']\n",
    "            messages.append(message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "for name in searched_names:\n",
    "    messages = find_messages_by_fl_name(name)\n",
    "    \n",
    "    print \"Имя [\", name, \"] найдено соответстивий (сообщений):\", len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление стоп-слов\n",
    "\n",
    "Так же, частью подготовки документов (постов с facebook) является удаление стоп-слов (stop-words), это слова которые не несут никакой значимой информации и никак не отображают тему текста. В русском это были бы слова \"а\", \"и\", \"или\", \"в\" и тд. Эти слова встречаются в всюду и избавившись от них мы сделаем наши данные чище.\n",
    "\n",
    "Список стоп-слов для английского языка лежат в отдельном файле с иминем \"stop-words.txt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря стоп-слов: 323 слова\n"
     ]
    }
   ],
   "source": [
    "def load_stop_words(file_name):\n",
    "    words = set()\n",
    "\n",
    "    f = open(file_name, 'r')\n",
    "\n",
    "    for line in f:\n",
    "        words.add(line.strip())\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return words\n",
    "\n",
    "stop_words = load_stop_words(\"stop_words.txt\")\n",
    "print \"Размер словаря стоп-слов:\", len(stop_words), \"слова\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пакет <b>scikit-learn</b> уже содержит список стоп-слов для английского языка, и что бы не упустить ничего, объеденим их словарь с нашим (тот, который мы выгрузили с файла ранее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер объедененного словаря стоп-слов: 323 слова\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "\n",
    "\n",
    "stop_wrods = text.ENGLISH_STOP_WORDS.union(stop_words)\n",
    "print \"Размер объедененного словаря стоп-слов:\", len(stop_words), \"слова\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация данных\n",
    "\n",
    "Добавим процедуру стемминга в <b>CountVectorizer</b> через наследование, создав новый класс <b>StemmedCountVectorizer</b>. Использован стиммер Портера из модуля <b>nltk</b>. Сам же стиммер будет использован после этапа токенизации и до формирования списка токенов по обработаному корпусу в вектооризаторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def __init__(self):\n",
    "        super(StemmedCountVectorizer, self).__init__()\n",
    "        self.stemmer = PorterStemmer()  # проинициализируем стиммер Портера\n",
    "        self.stop_words = stop_words    # проинициализируем словарь стоп-слов\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc:(self.stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "def create_vectorizer(): return StemmedCountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование списка топ 100 важных токенов по каждой категории\n",
    "\n",
    "Выполним запрос к базе данных, что бы вытащить списко всех категорий (тех, что мы записывали в базу данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = fdb.get_all_domains()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим словарь, где ключем будет служить имя домена, а значением посты по этому домену."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время получения постов с базы данных -> 774\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "posts = dict([(domain, fdb.get_messages_by_domain(domain)) for domain in domains])\n",
    "f_time = time()\n",
    "\n",
    "print \"Время получения постов с базы данных ->\", (f_time - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во постов [ pokemon_go ]: 349\n",
      "Кол-во постов [ music      ]: 7986\n",
      "Кол-во постов [ politics   ]: 7304\n",
      "Кол-во постов [ tech       ]: 11986\n",
      "Кол-во постов [ sport      ]: 1117\n",
      "Кол-во постов [ finances   ]: 7592\n"
     ]
    }
   ],
   "source": [
    "for k, v in posts.items():\n",
    "    print \"Кол-во постов [\", \"{0: <10}\".format(str(k)), \"]:\", len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что бы работать с каждым классом независимо, создаем для каждого класса свой векторизатор, так как векторизатор кеширует список токенов трансформированного корпуса. Векторизаторы (в данном случае CountVectorizer) будут хранится в словаре, под ключем имени категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs = dict([(domain, create_vectorizer()) for domain in domains])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь векторизируем с помощью соответствующего векторизатора, соответствующий корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Словарь => key=\"имя_домена\", value=\"матрица векторов соответствующего корпуса\"\n",
    "xs = dict([(domain, vs[domain].fit_transform(posts[domain])) for domain in domains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры словарей [ pokemon_go ]: 1085\n",
      "Размеры словарей [ music      ]: 5997\n",
      "Размеры словарей [ politics   ]: 38471\n",
      "Размеры словарей [ tech       ]: 11110\n",
      "Размеры словарей [ sport      ]: 3144\n",
      "Размеры словарей [ finances   ]: 9372\n"
     ]
    }
   ],
   "source": [
    "for k, v in vs.items():\n",
    "    print \"Размеры словарей [\", \"{0: <10}\".format(str(k)), \"]:\", len(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя разряженную матрицу векторов, полученную от <b>CountVectorizer</b>, посчитаем кол-во вхождений каждого слова во всех документах (постах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_top_tokens(matrix, vocabulary, amount, domain_name=None):\n",
    "    s_time = time()\n",
    "    \n",
    "    counts = [(word, matrix.getcol(col_num).sum()) for word, col_num in vocabulary.items()]\n",
    "    tokens = sorted(counts, key = lambda x: -x[1])[:min(amount, len(counts))]\n",
    "    tokens_res = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        tokens_res.append((token[0], i))\n",
    "    \n",
    "    f_time = time()\n",
    "    \n",
    "    if domain_name == None:\n",
    "        print \"Время поиска [\", amount, \"] популярных токенов ->\", (f_time - s_time)\n",
    "    else:\n",
    "        print \"Время поиска [\", \"{0: <10}\".format(domain_name), \"-\", amount, \"] популярных токенов ->\", (f_time - s_time)\n",
    "        \n",
    "    return tokens_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время поиска [ tech       - 100 ] популярных токенов -> 8104\n",
      "Время поиска [ music      - 100 ] популярных токенов -> 2573\n",
      "Время поиска [ finances   - 100 ] популярных токенов -> 4576\n",
      "Время поиска [ politics   - 100 ] популярных токенов -> 71886\n",
      "Время поиска [ sport      - 100 ] популярных токенов -> 410\n",
      "Время поиска [ pokemon_go - 100 ] популярных токенов -> 74\n"
     ]
    }
   ],
   "source": [
    "top_words_dict = dict([(d, find_top_tokens(xs[d], vs[d].vocabulary_, 100, d)) for d in domains])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим из каждого списка сеты, что бы воспользоватся возможностями множеств для решения задачи классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_set = dict([(d, set(w[0] for w in top_words_dict[d])) for d in domains])\n",
    "len(top_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Несколько популярных слов со списка [ pokemon_go ]:\n",
      "[(u'pokemon', 0), (u'app', 1), (u'gym', 2), (u'catch', 3), (u'just', 4)] ...\n",
      "\n",
      "Несколько популярных слов со списка [ music      ]:\n",
      "[(u'new', 0), (u'mtv', 1), (u'like', 2), (u'just', 3), (u'look', 4)] ...\n",
      "\n",
      "Несколько популярных слов со списка [ politics   ]:\n",
      "[(u'china', 0), (u'trump', 1), (u'news', 2), (u'say', 3), (u'donald', 4)] ...\n",
      "\n",
      "Несколько популярных слов со списка [ tech       ]:\n",
      "[(u'new', 0), (u'ti', 1), (u'make', 2), (u'just', 3), (u'like', 4)] ...\n",
      "\n",
      "Несколько популярных слов со списка [ sport      ]:\n",
      "[(u'team', 0), (u'sport', 1), (u'like', 2), (u'best', 3), (u'player', 4)] ...\n",
      "\n",
      "Несколько популярных слов со списка [ finances   ]:\n",
      "[(u'cnnmon', 0), (u'year', 1), (u'cnntech', 2), (u'money', 3), (u'make', 4)] ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in top_words_dict.items():\n",
    "    print \"Несколько популярных слов со списка [\", \"{0: <10}\".format(str(k)), \"]:\"\n",
    "    print v[:min(len(v), 5)], \"...\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Категоризация новых текстов (определение домена текста)\n",
    "\n",
    "Алгоритм определения домена (класса) текста:\n",
    "1. Найти пересечение множества слова текста с множествами топ-100 слов по каждой категории\n",
    "2. Посмотреть колличественно на размер пересечений и склонится в сторону большего\n",
    "3. Если категории равны по размеру пересечений, найти вес каждого пересечения отталкиваясь от позиции кажлого слова пересечения в списке топ-100 слов по каждой категории, т.е. чем выше в списке, тем вес слова больше.\n",
    "4. В случае, если и тут несколько категорий равносильны, сделать выбор сравнив имена категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "# Поиск элементов в итерируемых коллекциях\n",
    "def find_elm(iterable, predicate_):\n",
    "    for v in iterable:\n",
    "        if predicate_(v):\n",
    "            return v\n",
    "\n",
    "    return None\n",
    "\n",
    "# Для поиска категории к которой относится текст (функция find_domain(txt)), \n",
    "# нам понядобится один вектооризатор\n",
    "fd_vec = create_vectorizer()\n",
    "\n",
    "def find_domain(txt):\n",
    "    # Если список категорий пуст, то нечего искать\n",
    "    if len(domains) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Так векторизатор перезапишет свое состояние и можно будет получить список слов текста,\n",
    "    # в которых удалены стоп слова и выполнен стемминг\n",
    "    fd_vec.fit_transform([txt])\n",
    "    \n",
    "    # Теперь используя словарь данного текста - превратим его в сет,\n",
    "    # что необходимо для последующих манипуляций\n",
    "    words = [item[0] for item in fd_vec.vocabulary_.items()]\n",
    "    \n",
    "    # Сет слов текста\n",
    "    words_set = set(words)\n",
    "    \n",
    "    # Тут мы будем хранить пересечения словаря этого текста со словарями \n",
    "    # по каждой категории\n",
    "    res_buffer = []\n",
    "    \n",
    "    words_intersection_set = None\n",
    "    \n",
    "    # Сюда будем складывать результаты пересечений множеств слов текста и топ 100 по категориям\n",
    "    isds = []\n",
    "    \n",
    "    # Для каждого домена со списка\n",
    "    for domain in domains:\n",
    "        # Достаем для данного домена сет топ 100-та слов\n",
    "        domain_top_words_set = top_words_set[domain]\n",
    "        \n",
    "        # Находим пересечение словарей по категориям и словаря текста\n",
    "        words_intersection_set = words_set.intersection(domain_top_words_set)    \n",
    "        words_intersection_len = len(words_intersection_set)\n",
    "        \n",
    "        isds.append((domain, words_intersection_set))\n",
    "        res_buffer.append((domain, words_intersection_len))\n",
    "    \n",
    "    if len(res_buffer) == 1:\n",
    "        return res_buffer[0][0]\n",
    "\n",
    "    # Находим категорию с наибольшим кол-во пересечений\n",
    "    top_tuple = max(res_buffer, key=lambda t: t[1])\n",
    "    # Максимальное кол-во пересечений\n",
    "    max_count = (top_tuple)[1]\n",
    "    \n",
    "    # Формируем список из категорий с которыми одинаковое кол-во пересечений\n",
    "    res = [name for name, count in res_buffer if count == max_count]\n",
    "    \n",
    "    if len(res) == 0:\n",
    "        return None\n",
    "    \n",
    "    if len(res) == 1:\n",
    "        return res[0]\n",
    "    \n",
    "    # Имя результирующей категории (домена)\n",
    "    domain_res = None\n",
    "    # Вес результирующей категории (домена)\n",
    "    domain_vol = -1\n",
    "    \n",
    "    for domain in res:\n",
    "        # Находим вес для каждого слова в пересечениях с разными категориями\n",
    "        # чтобы по весу сказать какая категория преобладает\n",
    "        top_words = top_words_dict[domain]\n",
    "        \n",
    "        # Вес\n",
    "        vol = 0\n",
    "        \n",
    "        words_intersection_set = find_elm(isds, lambda e: e[0] == domain)[1]\n",
    "        \n",
    "        for w in words_intersection_set:\n",
    "            vol_tmp = find_elm(top_words, lambda e: e[0] == w)[1]\n",
    "            \n",
    "            if vol_tmp != None:\n",
    "                vol += vol_tmp\n",
    "        \n",
    "        # В случае, если и вес одинаков, сравниваем имена груп\n",
    "        # и выбор делаем в сторону большей\n",
    "        if vol > domain_vol:\n",
    "            domain_res = domain\n",
    "            domain_vol = vol\n",
    "        elif vol == domain_vol:\n",
    "            if domain > domain_res:\n",
    "                domain_res = domain\n",
    "                domain_vol = vol\n",
    "    \n",
    "    return domain_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем провести тестирование на заведомо известных документах, которые были классифицированы вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As islanders look forward to next year, many ... -> finances\n",
      "According to the Pentagon, Special Operation ... -> politics\n",
      "The Pentagon says staff can still play the ga... -> tech\n",
      "Intel's making drones now.... -> politics\n",
      "Samsung Mobile really pulled out all the stop... -> tech\n",
      "VR anywhere? Nvidia's GTX 10-series GPUs in n... -> tech\n",
      "'The Second Amendment was put in there not ju... -> politics\n",
      "Get ready... Britney Spears is performing at ... -> music\n",
      "Any idea why the 'ar' feature is always on wh... -> pokemon_go\n",
      "The best thing just happened to me.One of my ... -> pokemon_go\n",
      "So i have just checked a different iv calcula... -> pokemon_go\n",
      "Ronald Reagan's daughter Patti Davis is citin... -> finances\n",
      "If Hillary Clinton wins in November, she will... -> finances\n",
      "Even if you're mentally prepared for a high p... -> finances\n",
      "Under Armour founder and CEO Kevin Plank says... -> finances\n",
      "You never have to pay for student loan help. ... -> finances\n",
      "\n",
      "domains true: [3, 3, 0, 0, 0, 0, 1, 1, 5, 5, 5, 2, 2, 2, 2, 2]\n",
      "domains pred: [2, 3, 0, 3, 0, 0, 3, 1, 5, 5, 5, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "docs_test = [\n",
    "    (\"politics\",\"As islanders look forward to next year, many say they hope — and even expect — Hillary Clinton to spend at least part of her summer vacations on Martha's Vineyard if she becomes president.\"),\n",
    "    (\"politics\",\"According to the Pentagon, Special Operation Forces targeted and killed ISIS leader Hafiz Sayed Khan in Afghanistan.\"),\n",
    "    \n",
    "    (\"tech\", \"The Pentagon says staff can still play the game on their personal phones.\"),\n",
    "    (\"tech\", \"Intel's making drones now.\"),\n",
    "    (\"tech\", \"Samsung Mobile really pulled out all the stops on the new Galaxy Note 7\"),\n",
    "    (\"tech\", \"VR anywhere? Nvidia's GTX 10-series GPUs in notebooks make that a reality.\"),\n",
    "    \n",
    "    (\"music\", \"'The Second Amendment was put in there not just so we can go shoot skeet or go shoot trap. It was put in so we could defend our First Amendment, the freedom of speech, and also to defend ourselves against our own government,' says US Olympic skeet shooter Kim Rhode.\"),\n",
    "    (\"music\", \"Get ready... Britney Spears is performing at the 2016 Video Music Awards on August 28!\"),\n",
    "    \n",
    "    (\"pokemon_go\", \"Any idea why the 'ar' feature is always on when battling in gyms but not when catching Pokemon? (Ar option is off)\"),\n",
    "    (\"pokemon_go\", \"The best thing just happened to me.One of my fav pokemon is arcanine. I have a 640 growlithe with 39 candy. I was calculating my pokemom ivs when a growlithe appeared in my nearby list....so i put on shoes and went to track him down....i found him and while i was catching him i was thinking to myself that ill have 43 candies(3 and transfer) and i was like imagine if i find 2 more and i get an arcanine....after i caught him my 5k egg hatched and i was like no way it will be a growlithe and it was!!!!! A 746 growlithe which boosted me up to 60 candies ready to evolve !!!!!!!!!!!\"),\n",
    "    (\"pokemon_go\", \"So i have just checked a different iv calculator. I have been using silph road for some time and i just tried pokeassistant. They didnt match , i dont know what to think. There doesnt seem to be an accurate iv calculator\"),\n",
    "    \n",
    "    (\"finances\", \"Ronald Reagan's daughter Patti Davis is citing her father's shooting as evidence that comments like Donald J. Trump's recent blast against Hillary Clinton have real-world consequences.\"),\n",
    "    (\"finances\", \"If Hillary Clinton wins in November, she will be the first former secretary of state to take over the Oval Office since 1857.\"),\n",
    "    (\"finances\", \"Even if you're mentally prepared for a high priced ticket, some of the added travel costs associated with flying might throw you for a loop.\"),\n",
    "    (\"finances\", \"Under Armour founder and CEO Kevin Plank says if he's able to build his dream for the company in Baltimore it will create 'thousands to tens of thousands' of jobs, and says 'we see a vision here for us to make something greater'.\"), \n",
    "    (\"finances\", \"You never have to pay for student loan help. If you're eligible, your loan servicer will offer you lower monthly payments or debt forgiveness of your federal student loans for free.\")\n",
    "]\n",
    "    \n",
    "res_domains_true = []\n",
    "res_domains_pred = []\n",
    "\n",
    "for domain_true, doc in docs_test:\n",
    "    domain_pred = find_domain(doc)  \n",
    "    \n",
    "    res_domains_true.append(domains.index(domain_true))\n",
    "    res_domains_pred.append(domains.index(domain_pred))\n",
    "    \n",
    "    print doc[0:45] + \"...\", \"->\", domain_pred\n",
    "    \n",
    "print\n",
    "print \"domains true:\", res_domains_true\n",
    "print \"domains pred:\", res_domains_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества классификации\n",
    "\n",
    "Для оценки качества алгоритма классификации была выбрана <b>F1-score</b>, которая является относитеьно устойчивой под различные входные данные.\n",
    "\n",
    "<p><b>F1-score</b> - это гармоническое среднее между точностью и полнотой. В данном случае точность и полнота равноценны.</p>\n",
    "\n",
    "<p><b>Точность</b> <i>(precision)</i> – это доля документов действительно принадлежащих данному классу относительно всех документов которые система отнесла к этому классу.</p>\n",
    "<p><b>Полнота</b> <i>(recall)</i> – это доля найденных классфикатором документов принадлежащих классу относительно всех документов этого класса в тестовой выборке.</p>\n",
    "\n",
    "$$F1=2* \\frac{Precision*Recall}{Precision+Recall}$$\n",
    "\n",
    "В состав библиотеки <b>scikit-learn</b> входит реализация <b>F1-score</b> в виде функции <b>f1_score</b> из модуля <b>sklearn.metrics</b>\n",
    "\n",
    "Значение параметра <b>average</b> дает возможность по разному оценивать данные, к примеру в ситуациях, когда данных одного конкретного класса больше нежели остальных. Определяет некую стратегию подсчета F1-score:\n",
    "<p><b>weighted</b> - будет посчитано F1-score для каждого класса, а результатом будет их среднее значение, так же будет учтено кол-во эелементов по каждому классу, чем их больше тем важнее они воспринимаются</p>\n",
    "<p><b>micro</b> - общая оценка где рассматривается глобальное показатели</p>\n",
    "<p><b>macro</b> - будет посчитано F1-score для каждого класса, а результатом будет их среднее значение</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (micro)   : 0.8125\n",
      "F1-score (macro)   : 0.76658008658\n",
      "F1-score (weighted): 0.81920995671\n",
      "F1-score (None)    : [ 0.85714286  0.66666667  0.90909091  0.4         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print \"F1-score (micro)   :\", f1_score(res_domains_true, res_domains_pred, average=\"micro\")\n",
    "print \"F1-score (macro)   :\", f1_score(res_domains_true, res_domains_pred, average=\"macro\")\n",
    "print \"F1-score (weighted):\", f1_score(res_domains_true, res_domains_pred, average=\"weighted\")\n",
    "print \"F1-score (None)    :\", f1_score(res_domains_true, res_domains_pred, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
