{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Константы работы с базой данных <b>Elasticsearch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ES_INDEX = \"fb_group_posts\"\n",
    "ES_POST_DOC_TYPE = \"post\"\n",
    "ES_NAME_RELATION_DOC_TYPE = \"name_relation\"\n",
    "ES_BULK_ACTIONS_SIZE = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся работа с Elasticsearch скрыта в классе <b>FacebookDBHelper</b>, и предоставляет удобный интерфейс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import TransportError\n",
    "from elasticsearch import helpers\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class PostData(object):\n",
    "    def __init__(self, id_, messages):\n",
    "        self.id = id_\n",
    "        self.message = messages\n",
    "\n",
    "\n",
    "class FLNameData(object):\n",
    "    def __init__(self, fl_name, post_id):\n",
    "        self.fl_name = fl_name\n",
    "        self.post_id = post_id\n",
    "\n",
    "\n",
    "class FacebookDBHelper(object):\n",
    "    def __init__(self):\n",
    "        self.es = Elasticsearch()\n",
    "\n",
    "    def save_posts(self, group_name, group_domain, posts):\n",
    "        actions = []\n",
    "\n",
    "        for post in posts:\n",
    "            if 'message' in post.keys():\n",
    "                action = {\n",
    "                    \"_index\": ES_INDEX,\n",
    "                    \"_type\": ES_POST_DOC_TYPE,\n",
    "                    \"_id\": post['id'],\n",
    "                    \"_source\": {\n",
    "                        \"message\": post['message'],\n",
    "                        \"group_name\": group_name,\n",
    "                        \"group_domain\": group_domain\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                actions.append(action)\n",
    "\n",
    "        self.__bulk_insert(actions)\n",
    "\n",
    "    def save_name_relations(self, relations):\n",
    "        actions = []\n",
    "\n",
    "        for relation in relations:\n",
    "            action = {\n",
    "                \"_index\": ES_INDEX,\n",
    "                \"_type\": ES_NAME_RELATION_DOC_TYPE,\n",
    "                \"_source\": {\n",
    "                    \"fl_name\": relation.fl_name,\n",
    "                    \"post_id\": relation.post_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            actions.append(action)\n",
    "\n",
    "        self.__bulk_insert(actions)\n",
    "\n",
    "    def __bulk_insert(self, actions):\n",
    "        actions_list = split_list(list(actions), ES_BULK_ACTIONS_SIZE)\n",
    "\n",
    "        for acts in actions_list:\n",
    "            helpers.bulk(self.es, acts)\n",
    "\n",
    "    def get_post_by_id(self, id):\n",
    "        return self.__get(doc_type=ES_POST_DOC_TYPE, id=id)\n",
    "\n",
    "    def get_all_posts(self):\n",
    "        return self.__get_all(doc_type=ES_POST_DOC_TYPE)\n",
    "\n",
    "    def get_all_name_relations(self, doc_type):\n",
    "        relations = self.__get_all(doc_type=doc_type)\n",
    "\n",
    "        # noinspection PyTypeChecker\n",
    "        return [FLNameData(fl_name=r['_source']['fl_name'], post_id=r[\"_id\"]) for r in relations]\n",
    "\n",
    "    def __get(self, doc_type, id):\n",
    "        return self.es.get(index=ES_INDEX, doc_type=doc_type, id=id)\n",
    "\n",
    "    def __get_all(self, doc_type, body=None):\n",
    "        if body is None:\n",
    "            body = {}\n",
    "\n",
    "        result = []\n",
    "\n",
    "        page = self.es.search(\n",
    "            index=ES_INDEX,\n",
    "            doc_type=doc_type,\n",
    "            scroll='2m',\n",
    "            search_type='scan',\n",
    "            size=1000,\n",
    "            body=body)\n",
    "\n",
    "        scroll_id = page['_scroll_id']\n",
    "        scroll_size = page['hits']['total']\n",
    "\n",
    "        while scroll_size > 0:\n",
    "            page = self.es.scroll(scroll_id=scroll_id, scroll='2m')\n",
    "\n",
    "            scroll_id = page['_scroll_id']\n",
    "            scroll_size = len(page['hits']['hits'])\n",
    "\n",
    "            result.extend(page['hits']['hits'])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_all_sources(self, doc_type):\n",
    "        posts = self.get_all_posts()\n",
    "        result = []\n",
    "\n",
    "        for post in posts:\n",
    "            if \"_source\" in post.keys():\n",
    "                # noinspection PyTypeChecker\n",
    "                result.append(post[\"_source\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_all_messages(self):\n",
    "        sources = self.get_all_sources(doc_type=ES_POST_DOC_TYPE)\n",
    "        result = []\n",
    "\n",
    "        for source in sources:\n",
    "            if 'message' in source.keys():\n",
    "                # noinspection PyTypeChecker\n",
    "                result.append(source[\"message\"])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def delete_all_posts(self):\n",
    "        return delete_by_doc_type(\n",
    "            es=self.es,\n",
    "            index=ES_INDEX,\n",
    "            type_=ES_POST_DOC_TYPE)\n",
    "\n",
    "    def delete_all_name_relations(self):\n",
    "        return delete_by_doc_type(\n",
    "            es=self.es,\n",
    "            index=ES_INDEX,\n",
    "            type_=ES_NAME_RELATION_DOC_TYPE)\n",
    "\n",
    "    def get_messages_by_domain(self, domain):\n",
    "        posts = self.__get_all(doc_type=ES_POST_DOC_TYPE, body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"group_domain\": {\n",
    "                        \"query\": domain,\n",
    "                        \"operator\": \"and\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        return [p['_source']['message'] for p in posts]\n",
    "\n",
    "    def get_name_relations_by_fl(self, fl_name):\n",
    "        return self.__get_all(doc_type=ES_NAME_RELATION_DOC_TYPE, body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"fl_name\": {\n",
    "                        \"query\": fl_name,\n",
    "                        \"operator\": \"and\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    def get_all_domains(self):\n",
    "        response = self.es.search(index=ES_INDEX, doc_type=ES_POST_DOC_TYPE, body={\n",
    "            \"size\": 0,\n",
    "            \"aggs\": {\n",
    "                \"langs\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"group_domain\",\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for bucket in response['aggregations']['langs']['buckets']:\n",
    "            result.append(bucket['key'])\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def delete_by_doc_type(es, index, type_):\n",
    "    try:\n",
    "        count = es.count(index, type_)['count']\n",
    "        max_count = 5000\n",
    "\n",
    "        if not count:\n",
    "            return 0\n",
    "\n",
    "        tmp_count = count\n",
    "\n",
    "        while tmp_count > 0:\n",
    "            tmp_count -= max_count\n",
    "\n",
    "            response = es.search(\n",
    "                index=index,\n",
    "                filter_path=[\"hits.hits._id\"],\n",
    "                body={\"size\": max_count,\n",
    "                      \"query\": {\n",
    "                          \"filtered\": {\n",
    "                              \"filter\": {\n",
    "                                    \"type\": {\"value\": type_}\n",
    "                              }\n",
    "                          }\n",
    "                      }})\n",
    "\n",
    "            if not response:\n",
    "                return 0\n",
    "\n",
    "            ids = [x[\"_id\"] for x in response[\"hits\"][\"hits\"]]\n",
    "\n",
    "            if not ids:\n",
    "                return 0\n",
    "\n",
    "            bulk_body = [\n",
    "                '{{\"delete\": {{\"_index\": \"{}\", \"_type\": \"{}\", \"_id\": \"{}\"}}}}'.format(index, type_, x)\n",
    "                for x in ids]\n",
    "\n",
    "            es.bulk('\\n'.join(bulk_body))\n",
    "            es.indices.flush_synced([index])\n",
    "\n",
    "        return count\n",
    "    except TransportError as ex:\n",
    "        print(\"Elasticsearch error: \" + ex.error)\n",
    "        raise ex\n",
    "        \n",
    "def split_list(list_, count_):\n",
    "    result = []\n",
    "\n",
    "    if len(list_) == 0:\n",
    "        return result\n",
    "\n",
    "    if len(list_) == count_:\n",
    "        result.append(list_)\n",
    "\n",
    "        return result\n",
    "\n",
    "    steps = len(list_) / count_\n",
    "    tmp_list = deepcopy(list_)\n",
    "\n",
    "    for i in range(0, steps):\n",
    "        result.append(tmp_list[0: count_])\n",
    "        tmp_list = tmp_list[count_: len(tmp_list)]\n",
    "\n",
    "    if len(tmp_list) != 0:\n",
    "        result.append(tmp_list)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdb = FacebookDBHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же для измирения времени работы некоторых участоков подключим модуль <b>\"time\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time as t\n",
    "\n",
    "def time():\n",
    "    return int(round(t.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые константы для работы с <b>facebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FACEBOOK_TOKEN = \"1769775703259571|736fc7f9c5dc31707d40709a1d37813b\"\n",
    "FACEBOOK_POSTS_COUNT = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сущьность описывающая заведомо известные данные о группе в <b>Facebook</b>:\n",
    "* Имя\n",
    "* Id на facebook.com\n",
    "* Домен (класс) тематики группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, name, id, domain):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.domain = domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список групп, которые будут использованы для работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = [\n",
    "    Group(name=\"CNN Politics\", id=\"219367258105115\", domain=\"politics\"),\n",
    "    Group(name=\"SinoRuss\", id=\"1565161760380398\", domain=\"politics\"),\n",
    "    Group(name=\"Politics & Sociology\", id=\"1616754815303974\", domain=\"politics\"),\n",
    "    Group(name=\"CNN Money\", id=\"6651543066\", domain=\"finances\"),\n",
    "    Group(name=\"MTV\", id=\"7245371700\", domain=\"music\"),\n",
    "    Group(name=\"CNET\", id=\"7155422274\", domain=\"tech\"),\n",
    "    Group(name=\"TechCrunch\", id=\"8062627951\", domain=\"tech\"),\n",
    "    Group(name=\"Sport Addicts\", id=\"817513368382866\", domain=\"sport\"),\n",
    "    Group(name=\"Pokemon GO\", id=\"1745029562403910\", domain=\"pokemon_go\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с Facebook будем использовать <b>Facebook Graph API</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from facebook import GraphAPI\n",
    "\n",
    "graph = GraphAPI(access_token=FACEBOOK_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же нам понадобится модуль для совершения <b>HTTP</b> запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция загружающая последовательно посты пока не достигнет предела группы или ограничения по кол-ву."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_next_posts(posts, max_count):\n",
    "    result = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        if count > max_count:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            for post_data in posts['data']:\n",
    "                keys = post_data.keys()  # Так как мы нам нужны сами сообщения\n",
    "                                         # мы не включаем в результат посты без текстовых сообщений\n",
    "                if 'message' in keys:\n",
    "                    result.append(post_data)\n",
    "\n",
    "            # Меняем размер запрашиваемого пака (страницы) с постами, в уже сформированном запросе \n",
    "            # от Facebook Graph API\n",
    "            request = posts['paging']['next'].replace(\"limit=25\", \"limit=100\")\n",
    "\n",
    "            s_time = time()\n",
    "            posts = requests.get(request).json()\n",
    "            f_time = time()\n",
    "            \n",
    "            posts_count = len(posts['data'])\n",
    "            count += posts_count\n",
    "            \n",
    "            print \"Время загрузки пака постов ->\", (f_time - s_time), \"|\", \"кол-во:\", posts_count, \"|\", \"всего:\", count\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    print \"Общее кол-во загруженных постов группы ->\", count\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя ранее описанный список постов заполняем нашу базу данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время загрузки данных [ CNN Politics ] группы -> 1742\n",
      "Время загрузки первого пака постов -> 781\n",
      "Время загрузки пака постов -> 1150 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1090 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 2206 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 2346 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1842 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 2051 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 1738 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 1638 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 1882 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1805 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 2571 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 1923 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 2368 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 2181 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 2009 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 2933 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 2086 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 2154 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1956 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 2550 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 2541 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1547 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1644 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1865 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 3152 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 2042 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1537 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 1795 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 2443 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 2325 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1977 | кол-во: 100 | всего: 3100\n",
      "Общее кол-во загруженных постов группы -> 3100\n",
      "Время сохранение постов в БД -> 2659\n",
      "-------------------------\n",
      "Время загрузки данных [ International Friends of China & Russia ] группы -> 768\n",
      "Время загрузки первого пака постов -> 1097\n",
      "Время загрузки пака постов -> 1784 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1831 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1787 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 3653 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 8033 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 7681 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 2112 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 2461 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 2045 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 2352 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 2840 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 6271 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 7235 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 4165 | кол-во: 98 | всего: 1398\n",
      "Время загрузки пака постов -> 8618 | кол-во: 100 | всего: 1498\n",
      "Время загрузки пака постов -> 2831 | кол-во: 100 | всего: 1598\n",
      "Время загрузки пака постов -> 4931 | кол-во: 87 | всего: 1685\n",
      "Время загрузки пака постов -> 1751 | кол-во: 100 | всего: 1785\n",
      "Время загрузки пака постов -> 3798 | кол-во: 100 | всего: 1885\n",
      "Время загрузки пака постов -> 2331 | кол-во: 99 | всего: 1984\n",
      "Время загрузки пака постов -> 1748 | кол-во: 100 | всего: 2084\n",
      "Время загрузки пака постов -> 1324 | кол-во: 100 | всего: 2184\n",
      "Время загрузки пака постов -> 2362 | кол-во: 100 | всего: 2284\n",
      "Время загрузки пака постов -> 7618 | кол-во: 100 | всего: 2384\n",
      "Время загрузки пака постов -> 3007 | кол-во: 100 | всего: 2484\n",
      "Время загрузки пака постов -> 1902 | кол-во: 100 | всего: 2584\n",
      "Время загрузки пака постов -> 1883 | кол-во: 100 | всего: 2684\n",
      "Время загрузки пака постов -> 2666 | кол-во: 100 | всего: 2784\n",
      "Время загрузки пака постов -> 3431 | кол-во: 100 | всего: 2884\n",
      "Время загрузки пака постов -> 3662 | кол-во: 100 | всего: 2984\n",
      "Время загрузки пака постов -> 2683 | кол-во: 100 | всего: 3084\n",
      "Общее кол-во загруженных постов группы -> 3084\n",
      "Время сохранение постов в БД -> 1512\n",
      "-------------------------\n",
      "Время загрузки данных [ Politics & Sociology: Afterbirth ] группы -> 1334\n",
      "Время загрузки первого пака постов -> 1561\n",
      "Время загрузки пака постов -> 7162 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 2465 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 6784 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1703 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1146 | кол-во: 73 | всего: 473\n",
      "Время загрузки пака постов -> 1233 | кол-во: 56 | всего: 529\n",
      "Время загрузки пака постов -> 921 | кол-во: 66 | всего: 595\n",
      "Время загрузки пака постов -> 1629 | кол-во: 76 | всего: 671\n",
      "Время загрузки пака постов -> 1036 | кол-во: 59 | всего: 730\n",
      "Время загрузки пака постов -> 7258 | кол-во: 64 | всего: 794\n",
      "Время загрузки пака постов -> 3275 | кол-во: 81 | всего: 875\n",
      "Время загрузки пака постов -> 6240 | кол-во: 78 | всего: 953\n",
      "Время загрузки пака постов -> 5980 | кол-во: 87 | всего: 1040\n",
      "Время загрузки пака постов -> 1088 | кол-во: 81 | всего: 1121\n",
      "Время загрузки пака постов -> 1695 | кол-во: 22 | всего: 1143\n",
      "Время загрузки пака постов -> 1058 | кол-во: 0 | всего: 1143\n",
      "Общее кол-во загруженных постов группы -> 1143\n",
      "Время сохранение постов в БД -> 476\n",
      "-------------------------\n",
      "Время загрузки данных [ CNNMoney ] группы -> 642\n",
      "Время загрузки первого пака постов -> 800\n",
      "Время загрузки пака постов -> 1155 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1227 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1242 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 2132 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1578 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 4998 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 6930 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 2562 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 3375 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 2181 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 2148 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 2221 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1939 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 1635 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 1641 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 2890 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 3765 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 2542 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 3089 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 10141 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 2637 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 7577 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 1854 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 3706 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 1913 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 3992 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 7482 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 2655 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 3173 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 2763 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 2764 | кол-во: 100 | всего: 3100\n",
      "Общее кол-во загруженных постов группы -> 3100\n",
      "Время сохранение постов в БД -> 1549\n",
      "-------------------------\n",
      "Время загрузки данных [ MTV ] группы -> 1316\n",
      "Время загрузки первого пака постов -> 1229\n",
      "Время загрузки пака постов -> 1535 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1235 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 6468 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1604 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 2267 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 3578 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 3880 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 4224 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 3470 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 6762 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 3275 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 3765 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 7174 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 2712 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 3578 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 8119 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 2781 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 6654 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1945 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 2876 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 2577 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 2527 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 7296 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 2649 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 2323 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 8210 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 2886 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 2541 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 2043 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 3275 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 3516 | кол-во: 100 | всего: 3100\n",
      "Общее кол-во загруженных постов группы -> 3100\n",
      "Время сохранение постов в БД -> 1662\n",
      "-------------------------\n",
      "Время загрузки данных [ CNET ] группы -> 1578\n",
      "Время загрузки первого пака постов -> 1969\n",
      "Время загрузки пака постов -> 1413 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1839 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 1639 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 2963 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 1738 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 2058 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 2763 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 2451 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 6652 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1855 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 1640 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 2204 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1878 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 3338 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 2916 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 1935 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 1941 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 2382 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 1713 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 3272 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 2065 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 2238 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 2153 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 1836 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 6558 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 2561 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 3988 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 2655 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 1948 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 1950 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 1741 | кол-во: 100 | всего: 3100\n",
      "Общее кол-во загруженных постов группы -> 3100\n",
      "Время сохранение постов в БД -> 1324\n",
      "-------------------------\n",
      "Время загрузки данных [ TechCrunch ] группы -> 1221\n",
      "Время загрузки первого пака постов -> 1236\n",
      "Время загрузки пака постов -> 1437 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 1225 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 2043 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 2514 | кол-во: 100 | всего: 400\n",
      "Время загрузки пака постов -> 2329 | кол-во: 100 | всего: 500\n",
      "Время загрузки пака постов -> 2222 | кол-во: 100 | всего: 600\n",
      "Время загрузки пака постов -> 2148 | кол-во: 100 | всего: 700\n",
      "Время загрузки пака постов -> 2250 | кол-во: 100 | всего: 800\n",
      "Время загрузки пака постов -> 3179 | кол-во: 100 | всего: 900\n",
      "Время загрузки пака постов -> 1945 | кол-во: 100 | всего: 1000\n",
      "Время загрузки пака постов -> 2147 | кол-во: 100 | всего: 1100\n",
      "Время загрузки пака постов -> 3277 | кол-во: 100 | всего: 1200\n",
      "Время загрузки пака постов -> 1841 | кол-во: 100 | всего: 1300\n",
      "Время загрузки пака постов -> 2764 | кол-во: 100 | всего: 1400\n",
      "Время загрузки пака постов -> 2452 | кол-во: 100 | всего: 1500\n",
      "Время загрузки пака постов -> 7165 | кол-во: 100 | всего: 1600\n",
      "Время загрузки пака постов -> 3078 | кол-во: 100 | всего: 1700\n",
      "Время загрузки пака постов -> 1946 | кол-во: 100 | всего: 1800\n",
      "Время загрузки пака постов -> 7059 | кол-во: 100 | всего: 1900\n",
      "Время загрузки пака постов -> 3177 | кол-во: 100 | всего: 2000\n",
      "Время загрузки пака постов -> 2053 | кол-во: 100 | всего: 2100\n",
      "Время загрузки пака постов -> 1733 | кол-во: 100 | всего: 2200\n",
      "Время загрузки пака постов -> 2044 | кол-во: 100 | всего: 2300\n",
      "Время загрузки пака постов -> 3175 | кол-во: 100 | всего: 2400\n",
      "Время загрузки пака постов -> 6659 | кол-во: 100 | всего: 2500\n",
      "Время загрузки пака постов -> 2044 | кол-во: 100 | всего: 2600\n",
      "Время загрузки пака постов -> 1950 | кол-во: 100 | всего: 2700\n",
      "Время загрузки пака постов -> 2565 | кол-во: 100 | всего: 2800\n",
      "Время загрузки пака постов -> 2009 | кол-во: 100 | всего: 2900\n",
      "Время загрузки пака постов -> 3240 | кол-во: 100 | всего: 3000\n",
      "Время загрузки пака постов -> 2270 | кол-во: 100 | всего: 3100\n",
      "Общее кол-во загруженных постов группы -> 3100\n",
      "Время сохранение постов в БД -> 1478\n",
      "-------------------------\n",
      "Время загрузки данных [ Sports Addicts ] группы -> 1002\n",
      "Время загрузки первого пака постов -> 1132\n",
      "Время загрузки пака постов -> 1648 | кол-во: 94 | всего: 94\n",
      "Время загрузки пака постов -> 3083 | кол-во: 98 | всего: 192\n",
      "Время загрузки пака постов -> 3260 | кол-во: 93 | всего: 285\n",
      "Время загрузки пака постов -> 923 | кол-во: 86 | всего: 371\n",
      "Время загрузки пака постов -> 1182 | кол-во: 81 | всего: 452\n",
      "Время загрузки пака постов -> 1243 | кол-во: 87 | всего: 539\n",
      "Время загрузки пака постов -> 6114 | кол-во: 87 | всего: 626\n",
      "Время загрузки пака постов -> 1449 | кол-во: 94 | всего: 720\n",
      "Время загрузки пака постов -> 1327 | кол-во: 100 | всего: 820\n",
      "Время загрузки пака постов -> 1428 | кол-во: 90 | всего: 910\n",
      "Время загрузки пака постов -> 2277 | кол-во: 100 | всего: 1010\n",
      "Время загрузки пака постов -> 6029 | кол-во: 90 | всего: 1100\n",
      "Время загрузки пака постов -> 1319 | кол-во: 93 | всего: 1193\n",
      "Время загрузки пака постов -> 1689 | кол-во: 95 | всего: 1288\n",
      "Время загрузки пака постов -> 1393 | кол-во: 93 | всего: 1381\n",
      "Время загрузки пака постов -> 1242 | кол-во: 51 | всего: 1432\n",
      "Время загрузки пака постов -> 1333 | кол-во: 0 | всего: 1432\n",
      "Общее кол-во загруженных постов группы -> 1432\n",
      "Время сохранение постов в БД -> 743\n",
      "-------------------------\n",
      "Время загрузки данных [ Pokémon GO Malta - Official ] группы -> 1696\n",
      "Время загрузки первого пака постов -> 2608\n",
      "Время загрузки пака постов -> 1883 | кол-во: 100 | всего: 100\n",
      "Время загрузки пака постов -> 989 | кол-во: 100 | всего: 200\n",
      "Время загрузки пака постов -> 2988 | кол-во: 100 | всего: 300\n",
      "Время загрузки пака постов -> 1348 | кол-во: 72 | всего: 372\n",
      "Время загрузки пака постов -> 915 | кол-во: 0 | всего: 372\n",
      "Общее кол-во загруженных постов группы -> 372\n",
      "Время сохранение постов в БД -> 323\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    # Получаем данные о группе по ее id на facebook.com\n",
    "    s_time = time()\n",
    "    group_json = graph.get_object(group.id)\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки данных [', group_json['name'], '] группы ->', (f_time - s_time)\n",
    "    \n",
    "    # Получаем первый пак постов, используем уже для этого метод \"get_connections\"\n",
    "    # который, грубо говоря, дает возможность запрашивать списки\n",
    "    s_time = time()\n",
    "    first_posts_pack = graph.get_connections(group_json['id'], 'feed')\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки первого пака постов ->', (f_time - s_time)\n",
    "    \n",
    "    # Последовательно загружаем все последующие посты\n",
    "    posts = load_next_posts(posts=first_posts_pack, max_count=FACEBOOK_POSTS_COUNT)\n",
    "    \n",
    "    # Сохраняем все в базу данных\n",
    "    s_time = time()\n",
    "    fdb.save_posts(group.name, group.domain, posts)\n",
    "    f_time = time()\n",
    "    \n",
    "    print \"Время сохранение постов в БД ->\", (f_time - s_time)\n",
    "    print \"-------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как двигатся дальше мы должны вытащить все имена, сформировав отношение \"имя <-> пост\", для последующего использования этих отношений при поиске. Логично, что это следует сделать перед дальнейшей обработкой и работы с постами, так как мы можем утратить часть имен в дальнейшем.\n",
    "\n",
    "Для того, что бы отискать все имена, мы воспользуемся регулярными выражениями, в данном случае, самой простой реализацией, которая даст много мусора, но в данном случае это не страшно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "FIRST_LAST_NAME_PATTERN = \"[A-Z]{1}[a-z]+\\s+[A-Z]{1}[a-z]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем пользоваться уже сохраненными данными (тем что сохранили ранее в базу данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время поиска имен по шаблону -> 251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30265"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = fdb.get_all_posts() # Вытаскиваем все посты\n",
    "name_relations = []\n",
    "\n",
    "s_time = time()\n",
    "\n",
    "for post in posts:\n",
    "    message = post['_source']['message']\n",
    "    names = re.findall(FIRST_LAST_NAME_PATTERN, message)\n",
    "\n",
    "    if names:\n",
    "        id = post['_id']\n",
    "\n",
    "        for name in names:\n",
    "            name = name.replace(\".\", \"\")\n",
    "            relation = FLNameData(fl_name=name, post_id=id)\n",
    "            name_relations.append(relation)\n",
    "\n",
    "f_time = time()\n",
    "\n",
    "print \"Время поиска имен по шаблону ->\", (f_time - s_time)\n",
    "    \n",
    "len(name_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку все отношения мы так же будем хранить в базе данных, то очистим ранее созданные связи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время удаления старых отношений 'сообщение <=> имя' -> 4\n",
      "Удалено старых отношений: 0\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "deleted_posts = fdb.delete_all_name_relations()\n",
    "f_time = time()\n",
    "\n",
    "print \"Время удаления старых отношений 'сообщение <=> имя' ->\", (f_time - s_time)\n",
    "print \"Удалено старых отношений:\", deleted_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время сохранения новых отношений 'сообщение <=> имя' -> 14836\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "fdb.save_name_relations(name_relations)\n",
    "f_time = time()\n",
    "\n",
    "print \"Время сохранения новых отношений 'сообщение <=> имя' ->\", (f_time - s_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как работает поиск. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имя [ John Kerry ] найдено соответстивий (сообщений): 19\n",
      "Имя [ Paul Reichler ] найдено соответстивий (сообщений): 10\n",
      "Имя [ Donald Trump ] найдено соответстивий (сообщений): 185\n"
     ]
    }
   ],
   "source": [
    "searched_names = [\n",
    "    \"John Kerry\",\n",
    "    \"Paul Reichler\",\n",
    "    \"Donald Trump\"\n",
    "]\n",
    "\n",
    "def find_messages_by_fl_name(fl_name):\n",
    "    finded_relations = fdb.get_name_relations_by_fl(fl_name=fl_name)\n",
    "    messages = []\n",
    "    finded_post_ids = set() # Необходимо, что бы учитывать ранее найденные посты\n",
    "\n",
    "    for relation in finded_relations:\n",
    "        post_id = relation['_source']['post_id']\n",
    "\n",
    "        if not post_id in finded_post_ids:\n",
    "            finded_post_ids.add(post_id)\n",
    "            \n",
    "            message = fdb.get_post_by_id(post_id)['_source']['message']\n",
    "            messages.append(message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "for name in searched_names:\n",
    "    messages = find_messages_by_fl_name(name)\n",
    "    \n",
    "    print \"Имя [\", name, \"] найдено соответстивий (сообщений):\", len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stop_words_loader import StopWordsLoader\n",
    "\n",
    "stop_words = StopWordsLoader(\"stop_words\").get()\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    return stem_tokens(tokens, stemmer)\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    \n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_wrods = text.ENGLISH_STOP_WORDS.union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = fdb.get_all_domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время получения постов с базы данных -> 502\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "posts = dict([(domain, fdb.get_messages_by_domain(domain)) for domain in domains])\n",
    "f_time = time()\n",
    "\n",
    "print \"Время получения постов с базы данных ->\", (f_time - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во постов [ pokemon_go ]: 338\n",
      "Кол-во постов [ music      ]: 3009\n",
      "Кол-во постов [ tech       ]: 5467\n",
      "Кол-во постов [ politics   ]: 5576\n",
      "Кол-во постов [ sport      ]: 1092\n",
      "Кол-во постов [ finances   ]: 2652\n"
     ]
    }
   ],
   "source": [
    "for k, v in posts.items():\n",
    "    print \"Кол-во постов [\", \"{0: <10}\".format(str(k)), \"]:\", len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_vectorizer():\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.stop_words = stop_words\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "vs = dict([(domain, create_vectorizer()) for domain in domains])\n",
    "xs = dict([(domain, vs[domain].fit_transform(posts[domain])) for domain in domains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры словарей [ pokemon_go ]: 1154\n",
      "Размеры словарей [ music      ]: 3965\n",
      "Размеры словарей [ tech       ]: 10441\n",
      "Размеры словарей [ politics   ]: 44167\n",
      "Размеры словарей [ sport      ]: 3541\n",
      "Размеры словарей [ finances   ]: 8218\n"
     ]
    }
   ],
   "source": [
    "for k, v in vs.items():\n",
    "    print \"Размеры словарей [\", \"{0: <10}\".format(str(k)), \"]:\", len(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_top_tokens(matrix, items, amount):\n",
    "    s_time = time()\n",
    "    counts = [(word, matrix.getcol(col_num).sum()) for word, col_num in items]\n",
    "    tokens = sorted (counts, key = lambda x: -x[1])[:min(amount, len(counts))]\n",
    "    f_time = time()\n",
    "    \n",
    "    print \"Время поиска [\", amount, \"] популярных токенов ->\", (f_time - s_time)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время поиска [ 100 ] популярных токенов -> 73756\n",
      "Время поиска [ 100 ] популярных токенов -> 3972\n",
      "Время поиска [ 100 ] популярных токенов -> 814\n",
      "Время поиска [ 100 ] популярных токенов -> 2113\n",
      "Время поиска [ 100 ] популярных токенов -> 472\n",
      "Время поиска [ 100 ] популярных токенов -> 84\n"
     ]
    }
   ],
   "source": [
    "pw = dict([(domain, find_top_tokens(xs[domain], vs[domain].vocabulary_.items(), 100)) for domain in domains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Несколько популярных слов со списка [ pokemon_go ]:\n",
      "[(u'pokemon', 66), (u'app', 19), (u'just', 17), (u'game', 16), (u'catch', 15)] \n",
      "\n",
      "Несколько популярных слов со списка [ music      ]:\n",
      "[(u'new', 139), (u'like', 127), (u'mtv', 106), (u'just', 94), (u'live', 82)] \n",
      "\n",
      "Несколько популярных слов со списка [ tech       ]:\n",
      "[(u'new', 347), (u'apple', 203), (u'like', 189), (u'cnet', 188), (u'just', 186)] \n",
      "\n",
      "Несколько популярных слов со списка [ politics   ]:\n",
      "[(u'china', 2379), (u'news', 1797), (u'trump', 1611), (u'media', 1401), (u'isis', 1389)] \n",
      "\n",
      "Несколько популярных слов со списка [ sport      ]:\n",
      "[(u'sports', 124), (u'team', 109), (u'like', 99), (u'nfl', 82), (u'best', 81)] \n",
      "\n",
      "Несколько популярных слов со списка [ finances   ]:\n",
      "[(u'cnnmon', 2576), (u'cnntech', 321), (u'new', 170), (u'trump', 167), (u'world', 122)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in pw.items():\n",
    "    print \"Несколько популярных слов со списка [\", \"{0: <10}\".format(str(k)), \"]:\"\n",
    "    print v[:min(len(v), 5)], \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Превращаем списки самых популярных слов в <b>SET-ы</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pws = dict([(domain, set([p1 for p1, p2 in pw[domain]])) for domain in domains])\n",
    "len(pws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_test = [\n",
    "    \"As islanders look forward to next year, many say they hope — and even expect — Hillary Clinton to spend at least part of her summer vacations on Martha's Vineyard if she becomes president.\",\n",
    "    \"The Pentagon says staff can still play the game on their personal phones.\",\n",
    "    \"Ronald Reagan's daughter Patti Davis is citing her father's shooting as evidence that comments like Donald J. Trump's recent blast against Hillary Clinton have real-world consequences.\",\n",
    "    \"If Hillary Clinton wins in November, she will be the first former secretary of state to take over the Oval Office since 1857.\",\n",
    "    \"Donald J. Trump and the billionaire Italian media mogul turned politician are both known for their larger than life personalities, their skills in capturing the attention of the press and shaping narratives in the media. Silvio Berlusconi served as Italy's prime minister for a total of nine years.\",\n",
    "    \"'The Second Amendment was put in there not just so we can go shoot skeet or go shoot trap. It was put in so we could defend our First Amendment, the freedom of speech, and also to defend ourselves against our own government,' says US Olympic skeet shooter Kim Rhode.\",\n",
    "    \"According to the Pentagon, Special Operation Forces targeted and killed ISIS leader Hafiz Sayed Khan in Afghanistan.\",\n",
    "    \"pokemon cool game play\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As islanders look forward to next year, many ... -> [u'finances']\n",
      "The Pentagon says staff can still play the ga... -> [u'sport', u'pokemon_go']\n",
      "Ronald Reagan's daughter Patti Davis is citin... -> [u'politics', u'finances']\n",
      "If Hillary Clinton wins in November, she will... -> [u'politics']\n",
      "Donald J. Trump and the billionaire Italian m... -> [u'politics', u'music', u'finances']\n",
      "'The Second Amendment was put in there not ju... -> [u'politics']\n",
      "According to the Pentagon, Special Operation ... -> [u'politics']\n",
      "pokemon cool game play... -> [u'pokemon_go']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "fd_vec = create_vectorizer()\n",
    "\n",
    "\n",
    "def find_domain(txt):\n",
    "    fd_vec.fit_transform([txt])\n",
    "    \n",
    "    words = [p1 for p1, p2 in fd_vec.vocabulary_.items()]\n",
    "    words_set = set(words)\n",
    "    \n",
    "    res_buffer = []\n",
    "    \n",
    "    for domain in domains:\n",
    "        domain_top_words_set = pws[domain]\n",
    "        \n",
    "        words_intersection_set = words_set.intersection(domain_top_words_set)    \n",
    "        words_intersection_len = len(words_intersection_set)\n",
    "        \n",
    "        res_buffer.append((domain, words_intersection_len))\n",
    "    \n",
    "    res_buffer_len = len(res_buffer)\n",
    "    \n",
    "    if res_buffer_len == 0:\n",
    "        return \"not found\"\n",
    "    \n",
    "    if res_buffer_len == 1:\n",
    "        return res_buffer[0][0]\n",
    "\n",
    "    top_tuple = max(res_buffer, key=lambda t: t[1])\n",
    "    max_count = (top_tuple)[1]\n",
    "    \n",
    "    res = [name for name, count in res_buffer if count == max_count]\n",
    "    \n",
    "    return res\n",
    "\n",
    "        \n",
    "for doc in docs_test:\n",
    "    print doc[0:45] + \"...\", \"->\", find_domain(doc)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
