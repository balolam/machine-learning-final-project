{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from facebook import GraphAPI\n",
    "from facebook_database_helper import SimpleFacebookDBHelper\n",
    "from facebook_database_helper import NameRelation\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import time as t\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time():\n",
    "    return int(round(t.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constant(func):\n",
    "    # noinspection SpellCheckingInspection\n",
    "    def funcset(self, value):\n",
    "        raise TypeError\n",
    "\n",
    "    # noinspection SpellCheckingInspection\n",
    "    def funcget(self):\n",
    "        return func()\n",
    "\n",
    "    return property(funcget, funcset)\n",
    "\n",
    "\n",
    "# noinspection PyPep8Naming,PyMethodParameters\n",
    "class _Const(object):\n",
    "    @constant\n",
    "    def FACEBOOK_TOKEN():\n",
    "        return \"1769775703259571|736fc7f9c5dc31707d40709a1d37813b\"\n",
    "\n",
    "    @constant\n",
    "    def FACEBOOK_POSTS_COUNT():\n",
    "        return 3000\n",
    "\n",
    "    @constant\n",
    "    def ES_INDEX():\n",
    "        return \"fb_group_posts\"\n",
    "\n",
    "    @constant\n",
    "    def ES_POSTS_DOC_TYPE():\n",
    "        return \"post\"\n",
    "    \n",
    "    @constant\n",
    "    def ES_NAMES_RELATIONS_DOC_TYPE():\n",
    "        return \"name_relations\"\n",
    "    \n",
    "    @constant\n",
    "    def ES_BULK_SIZE():\n",
    "        return 500\n",
    "\n",
    "\n",
    "CONST = _Const()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, name, id, domain):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.domain = domain\n",
    "        \n",
    "groups = [\n",
    "#     Group(name=\"CNN Politics\", id=\"219367258105115\", domain=\"politics\"),\n",
    "#     Group(name=\"SinoRuss\", id=\"1565161760380398\", domain=\"politics\"),\n",
    "#     Group(name=\"Politics & Sociology\", id=\"1616754815303974\", domain=\"politics\"),\n",
    "#     Group(name=\"CNN Money\", id=\"6651543066\", domain=\"finances\"),\n",
    "#     Group(name=\"MTV\", id=\"7245371700\", domain=\"music\"),\n",
    "#     Group(name=\"CNET\", id=\"7155422274\", domain=\"tech\"),\n",
    "#     Group(name=\"TechCrunch\", id=\"8062627951\", domain=\"tech\"),\n",
    "#     Group(name=\"Sport Addicts\", id=\"817513368382866\", domain=\"sport\"),\n",
    "#     Group(name=\"Pokemon GO\", id=\"1745029562403910\", domain=\"pokemon go\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = GraphAPI(access_token=CONST.FACEBOOK_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdb = SimpleFacebookDBHelper(\n",
    "    es=database, \n",
    "    index=CONST.ES_INDEX, \n",
    "    post_doc_type=CONST.ES_POSTS_DOC_TYPE, \n",
    "    name_relation_doc_type=CONST.ES_NAMES_RELATIONS_DOC_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pull_posts_from_pack(posts):\n",
    "    res = []\n",
    "\n",
    "    for p in posts['data']:\n",
    "        res.append(p)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_get_posts_request(posts):\n",
    "    return posts['paging']['next'].replace(\"limit=25\", \"limit=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_next_posts(posts, max_count):\n",
    "    result = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        if count > max_count:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            result.extend(pull_posts_from_pack(posts))\n",
    "\n",
    "            request = prepare_get_posts_request(posts)\n",
    "\n",
    "            s_time = time()\n",
    "            posts = requests.get(request).json()\n",
    "            f_time = time()\n",
    "            \n",
    "            posts_count = len(posts['data'])\n",
    "            count += posts_count\n",
    "            \n",
    "            print \"Время загрузки пака постов ->\", (f_time - s_time), \"|\", \"кол-во:\", posts_count, \"|\", \"всего:\", count\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    print \"Общее кол-во загруженных постов группы ->\", count\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    s_time = time()\n",
    "    group_json = graph.get_object(group.id)\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки данных [', group_json['name'], '] группы ->', (f_time - s_time)\n",
    "    \n",
    "    s_time = time()\n",
    "    first_posts_pack = graph.get_connections(group_json['id'], 'feed')\n",
    "    f_time = time()\n",
    "    \n",
    "    print 'Время загрузки первого пака постов ->', (f_time - s_time)\n",
    "    \n",
    "    posts = load_next_posts(posts=first_posts_pack, max_count=CONST.FACEBOOK_POSTS_COUNT)\n",
    "    \n",
    "    s_time = time()\n",
    "    fdb.save_posts(group.name, group.domain, posts)\n",
    "    f_time = time()\n",
    "    \n",
    "    print \"Время сохранение постов в БД ->\", (f_time - s_time)\n",
    "    print \"-------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIRST_LAST_NAME_PATTERN = \"[A-Z]{1}[a-z]+\\s+[A-Z]{1}[a-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdb.delete_all_name_relations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South China\n",
      "United States\n",
      "If China\n",
      "The Beijing\n",
      "Foreign Policy\n",
      "Pacific Ocean\n",
      "Manifest Destiny\n",
      "Pacific Power\n",
      "Johnny Come\n",
      "Johnny Come\n",
      "Hilary Clinton\n",
      "Asia Pivot\n",
      "American Empire\n",
      "Zionist Jewish\n",
      "Wall Street\n",
      "Big Oil\n",
      "Big Business\n",
      "Lib American\n",
      "South China\n",
      "United States\n",
      "If China\n",
      "The Beijing\n",
      "Foreign Policy\n",
      "Pacific Ocean\n",
      "Manifest Destiny\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = fdb.get_all_posts()\n",
    "name_relations = []\n",
    "\n",
    "for post in posts:\n",
    "    message = post['_source']['message']\n",
    "    names = re.findall(FIRST_LAST_NAME_PATTERN, message)\n",
    "\n",
    "    if names:\n",
    "        id = post['_id']\n",
    "\n",
    "        for name in names:\n",
    "            name = name.replace(\".\", \"\")\n",
    "            relation = NameRelation(fl_name=name, post_id=id)\n",
    "            name_relations.append(relation)\n",
    "\n",
    "for i in range(min(len(name_relations), 25)):\n",
    "    relation = name_relations[i]\n",
    "    print relation.fl_name\n",
    "    \n",
    "len(name_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время удаления старых отношений 'сообщение <=> имя' -> 2\n",
      "Удалено старых постов: 0\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "deleted_posts = fdb.delete_all_name_relations()\n",
    "f_time = time()\n",
    "\n",
    "print \"Время удаления старых отношений 'сообщение <=> имя' ->\", (f_time - s_time)\n",
    "print \"Удалено старых постов:\", deleted_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время сохранения новых отношений 'сообщение <=> имя' -> 21686\n"
     ]
    }
   ],
   "source": [
    "s_time = time()\n",
    "fdb.save_name_relations(name_relations)\n",
    "f_time = time()\n",
    "\n",
    "print \"Время сохранения новых отношений 'сообщение <=> имя' ->\", (f_time - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имя [ John Kerry ] найдено соответстивий: 25\n",
      "Пример сообщения: John Kerry ja USA jatkavat uhkailujen tiellä Venäjää ja Putinia vastaan.\n"
     ]
    }
   ],
   "source": [
    "searched_names = [\n",
    "    \"John Kerry\"\n",
    "]\n",
    "\n",
    "for name in searched_names:\n",
    "    messages = fdb.find_messages_by_fl_name(name)\n",
    "    print \"Имя [\", name, \"] найдено соответстивий:\", len(messages)\n",
    "    \n",
    "    if messages:\n",
    "        print \"Пример сообщения:\", messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stop_words_loader import StopWordsLoader\n",
    "\n",
    "stop_words = StopWordsLoader(\"stop_words\").get()\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset(['all', 'show', 'anyway', 'four', 'go', 'mill', 'find', 'seemed', 'whose', 're', 'herself', 'whoever', 'behind', 'should', 'to', 'only', 'under', 'herein', 'do', 'his', 'get', 'very', 'de', 'myself', 'cannot', 'every', 'yourselves', 'him', 'is', 'cry', 'beforehand', 'these', 'sh...ho', 'most', 'eight', 'but', 'nothing', 'why', 'noone', 'sometimes', 'together', 'serious', 'once']),\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x52151 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 180 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = fdb.get_all_messages()\n",
    "matrix = vectorizer.fit_transform(messages)\n",
    "\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are ok   -> 0\n",
      "are      -> 0\n",
      "ok       -> 7.80515472722\n",
      "classroom interface -> 0\n",
      "classroom -> 0.597431507586\n",
      "interface -> 2.16770873439\n"
     ]
    }
   ],
   "source": [
    "def get_words_count(token, vocabulary, x):\n",
    "    index = vocabulary.get(token)\n",
    "    \n",
    "    if index is None:\n",
    "        return 0\n",
    "    \n",
    "    return sum(x[:, index])[0, 0]\n",
    "\n",
    "words2 = [\n",
    "    \"are ok\", \"are\", \"ok\", \"classroom interface\", \"classroom\", \"interface\"\n",
    "]\n",
    "\n",
    "for token in words2:\n",
    "    print \"{:8}\".format(token), \"->\", get_words_count(token, vectorizer.vocabulary_, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
